{"version":3,"sources":["webpack:///path---retouch-da1b51eac72ff7eca778.js","webpack:///./.cache/json/retouch.json"],"names":["webpackJsonp","382","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,iBAAAC,aAAA,2DAAAC,KAAA,WAAAC,MAAA,4YAAAC,MAAA,cAAAC,QAAA,qIAAAC,MAAA,UAAAC,SAAAC,QAAA,qDAAAC,MAAA,oMAAi7BC,MAAA,4BAAAC,QAAA,yCAAoIC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,iHAAAf,aAA+IC,KAAA,4BAAAE,KAAA,gBAAAI,MAAA,sBAAAE,QAAA,oOAAAH,QAAA,kFAAAE,QAAA,4+BAAAN,aAAA,sFAAAG,MAAA,iBAAAD,MAAA,+PAAAM,MAAA,oMAAy8DE,QAAA,yEAAAD,MAAA,0CAAkLK,MAASjB,KAAA,GAAAgB,GAAA,+GAAAf,aAA6IC,KAAA,4BAAAE,KAAA,aAAAI,MAAA,YAAAE,QAAA,wFAAAH,QAAA,2IAAAE,QAAA,kjBAAAN,aAAA,sEAAAG,MAAA,gBAAAD,MAAA,ubAAAM,MAAA,oMAAslDE,QAAA,mEAAAD,MAAA","file":"path---retouch-da1b51eac72ff7eca778.js","sourcesContent":["webpackJsonp([262858279625854],{\n\n/***/ 382:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"C++, GLSL\"],[\"software\",\"Volume\"],[\"3d\",\"OpenGL\"]],\"path\":\"/retouch\",\"about\":\"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.\",\"cover\":\"shining.jpg\",\"credits\":\"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University\",\"title\":\"ReTouch\",\"press\":[],\"links\":[[\"Github\",\"https://github.com/juniorxsound/ReTouch\"]],\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"tags\":[\"Machine Learning\",\"Tools\"],\"excerpt\":\"Edit and retouch any image in 2.5D.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/pulpfiction.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/pulp-fiction\",\"title\":\"Inside Pulp Fiction\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL/Pulp-Fiction-ARKit\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/22/ai-rips-objects-from-video-and-reimagines-them-in-3d-ar/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"Vice\",\"https://motherboard.vice.com/en_us/article/gywamy/cue-up-the-pulp-fiction-dance-scene-this-app-3d-projects-2d-movies-in-your-living-room\"],[\"Mashable\",\"http://mashable.france24.com/tech-business/20180130-films-volume-realite-augmentee-cinema-technologie\"],[\"UploadVR\",\"https://uploadvr.com/ar-app-brings-pulp-fiction-characters-living-room/\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/170014746561/volume-in-development-project-from-or-fleisher\"],[\"VRFocus\",\"https://www.vrfocus.com/2018/01/reconstruct-your-favourite-movie-in-ar/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/volume-ai-program-puts-2d-objects-3d-spaces.html\"],[\"Labroots\",\"https://www.labroots.com/trending/videos/11371/ai-tool-turns-video-into-3d-augmented-reality-experiences\"]],\"components\":[[\"code\",\"Python, C#, HLSL\"],[\"software\",\"Unity3D, Tensorflow\"],[\"3d\",\"ARKit, Volume\"]],\"cover\":\"pulp_cover.jpg\",\"about\":\"Inside Pulp Fiction is an experiment that uses machine learning to reconstruct Pulp Fiction's iconic dance scene in Augmented Reality. The experiment is a part of Volume, a machine learning driven tool to reconstruct 3D models from 2D images and video.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/iwJt4DM6mJA?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Step inside Pulp Fiction's iconic dance scene using augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/skeletron.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/skeletron\",\"title\":\"Skeletron\",\"links\":[[\"Presskit\",\"https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://drorayalon.com\\\">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/\"],[\"Tech Radar\",\"https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect\"],[\"GeekTime\",\"https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html\"],[\"FossBytes\",\"https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/\"]],\"components\":[[\"code\",\"C#, HLSL Python\"],[\"software\",\"Unity3D\"],[\"3d\",\"Tensorflow\"]],\"cover\":\"skeletron.jpg\",\"about\":\"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"500\\\" src=\\\"https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Predict joints and human skeleton position from real-time video.\",\"tags\":[\"Machine Learning\",\"Tools\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---retouch-da1b51eac72ff7eca778.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"C++, GLSL\"],[\"software\",\"Volume\"],[\"3d\",\"OpenGL\"]],\"path\":\"/retouch\",\"about\":\"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.\",\"cover\":\"shining.jpg\",\"credits\":\"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University\",\"title\":\"ReTouch\",\"press\":[],\"links\":[[\"Github\",\"https://github.com/juniorxsound/ReTouch\"]],\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"tags\":[\"Machine Learning\",\"Tools\"],\"excerpt\":\"Edit and retouch any image in 2.5D.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/pulpfiction.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/pulp-fiction\",\"title\":\"Inside Pulp Fiction\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL/Pulp-Fiction-ARKit\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/22/ai-rips-objects-from-video-and-reimagines-them-in-3d-ar/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"Vice\",\"https://motherboard.vice.com/en_us/article/gywamy/cue-up-the-pulp-fiction-dance-scene-this-app-3d-projects-2d-movies-in-your-living-room\"],[\"Mashable\",\"http://mashable.france24.com/tech-business/20180130-films-volume-realite-augmentee-cinema-technologie\"],[\"UploadVR\",\"https://uploadvr.com/ar-app-brings-pulp-fiction-characters-living-room/\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/170014746561/volume-in-development-project-from-or-fleisher\"],[\"VRFocus\",\"https://www.vrfocus.com/2018/01/reconstruct-your-favourite-movie-in-ar/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/volume-ai-program-puts-2d-objects-3d-spaces.html\"],[\"Labroots\",\"https://www.labroots.com/trending/videos/11371/ai-tool-turns-video-into-3d-augmented-reality-experiences\"]],\"components\":[[\"code\",\"Python, C#, HLSL\"],[\"software\",\"Unity3D, Tensorflow\"],[\"3d\",\"ARKit, Volume\"]],\"cover\":\"pulp_cover.jpg\",\"about\":\"Inside Pulp Fiction is an experiment that uses machine learning to reconstruct Pulp Fiction's iconic dance scene in Augmented Reality. The experiment is a part of Volume, a machine learning driven tool to reconstruct 3D models from 2D images and video.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/iwJt4DM6mJA?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Step inside Pulp Fiction's iconic dance scene using augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/skeletron.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/skeletron\",\"title\":\"Skeletron\",\"links\":[[\"Presskit\",\"https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://drorayalon.com\\\">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/\"],[\"Tech Radar\",\"https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect\"],[\"GeekTime\",\"https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html\"],[\"FossBytes\",\"https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/\"]],\"components\":[[\"code\",\"C#, HLSL Python\"],[\"software\",\"Unity3D\"],[\"3d\",\"Tensorflow\"]],\"cover\":\"skeletron.jpg\",\"about\":\"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"500\\\" src=\\\"https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Predict joints and human skeleton position from real-time video.\",\"tags\":[\"Machine Learning\",\"Tools\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/retouch.json\n// module id = 382\n// module chunks = 262858279625854"],"sourceRoot":""}