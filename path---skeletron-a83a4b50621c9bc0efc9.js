webpackJsonp([0x5c9b1cd56a8a],{389:function(e,t){e.exports={data:{markdownRemark:{html:"",frontmatter:{date:"June 17, 2018",components:[["code","C#, HLSL Python"],["software","Unity3D"],["3d","Tensorflow"]],path:"/skeletron",about:"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).",cover:"skeletron.jpg",credits:'Developed with <a target="_blank" href="https://drorayalon.com">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port',title:"Skeletron",press:[["The Next Web","https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/"],["Tech Radar","https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect"],["GeekTime","https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/"],["Android Headlines","https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html"],["FossBytes","https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/"]],links:[["Presskit","https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY"]],embed:'<iframe width="100%" height="500" src="https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',tags:["Machine Learning","Tools"],excerpt:"Predict joints and human skeleton position from real-time video."}}},pathContext:{prev:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/retouch.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-06-18T12:21:00+00:02",path:"/retouch",title:"ReTouch",links:[["Github","https://github.com/juniorxsound/ReTouch"]],credits:"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University",press:[],components:[["code","C++, GLSL"],["software","Volume"],["3d","OpenGL"]],cover:"shining.jpg",about:"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.",embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"Edit and retouch any image in 2.5D.",tags:["Machine Learning","Tools"]}},next:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/deathmask.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-06-16T12:30:00+00:02",path:"/death-mask",title:"Death Mask",links:[["Documentation","http://itp.orfleisher.com/2017/11/17/where-is-the-line-with-public-data/"]],credits:'Developed with <a target="_blank" href="http://agermanidis.com">Anastasis Germanidis</a>',press:[["Wired","https://www.wired.it/attualita/tech/2017/12/20/death-mask-realta-morte-previsione/"],["UploadVR","https://uploadvr.com/arkit-death-mask/"],["Next Reailty","https://next.reality.news/news/ar-experiment-adds-life-clock-anyone-with-face-0181330/"],["VRInside","https://vrinside.jp/news/death-mask/"],["Shiropen","https://shiropen.com/2017/11/29/29963"],["Owdin","https://owdin.live/2017/11/24/death-mask-combien-dannees-de-vie-vous-reste-t-il-version-realite-augmentee/"],["prosthetic knowledge","http://prostheticknowledge.tumblr.com/post/167809095736/death-mask-programming-project-from-or-fleisher"],["Realite Virtuelle","https://www.realite-virtuelle.com/death-mask-age-mort-2911"]],components:[["code","Swift"],["software","Blender, CoreML, AgeNet"],["3d","ARKit"]],cover:"deathmask_cover.png",about:"‘Death-Mask’ predicts how long people have to live and overlays that in the form of a “clock” above they’re heads in augmented reality. The project uses a machine learning model titled AgeNet for the prediction process. Once predicted it uses the average life expectancy in that location to try and estimate how long one has left.\nThe aesthetic inspiration derives from the concept of death masks. These are sculptures meant to symbolize the death of a person by casting his face (i.e creating a mask).",embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/OzndnZuvu2c?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"Predict how long people have to live in augmented reality.",tags:["Augmented Reality","Machine Learning","Experiment"]}}}}}});
//# sourceMappingURL=path---skeletron-a83a4b50621c9bc0efc9.js.map