{"version":3,"sources":["webpack:///path---tzina-d31edae681b1954c7c54.js","webpack:///./.cache/json/tzina.json"],"names":["webpackJsonp","396","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,iBAAAC,aAAA,0JAAAC,KAAA,SAAAC,MAAA,ytBAAAC,MAAA,YAAAC,QAAA,2NAAAC,MAAA,QAAAC,QAAA,6eAAAC,QAAA,mJAAAC,MAAA,gWAA0iEC,MAAA,mBAAAC,QAAA,6DAAgQC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,0GAAAf,aAAwIC,KAAA,4BAAAE,KAAA,WAAAI,MAAA,UAAAE,QAAA,+IAAAH,QAAA,2FAAAE,QAAA,oXAAAN,aAAA,2FAAAG,MAAA,WAAAD,MAAA,2fAAAM,MAAA,oMAA++CE,QAAA,6DAAAD,MAAA,uDAAmLK,MAASjB,KAAA,GAAAgB,GAAA,gHAAAf,aAA8IC,KAAA,4BAAAE,KAAA,cAAAI,MAAA,aAAAE,QAAA,gLAAAH,QAAA,GAAAE,SAAAN,aAAA,gGAAAG,MAAA,iBAAAD,MAAA,0pBAAAM,MAAA,GAAAE,QAAA,mCAAAD,MAAA","file":"path---tzina-d31edae681b1954c7c54.js","sourcesContent":["webpackJsonp([254679725877355],{\n\n/***/ 396:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"DepthKit, e-on Vue, Adobe Photoshop, Autodesk Maya, ffmpeg, Web Audio API and the WebVR API.\"],[\"3d\",\"Three.js\"]],\"path\":\"/tzina\",\"about\":\"In January 2017, Tzina Dizengoff square, one of Tel Aviv’s emblematic sites, was demolished. The square became a home for the lonely and marginalized characters of the area. This project tells the story of the people who gravitated toward the square and spent their days in it. In this interactive webVR documentary, they talk about their lives and the square. Together, they form a poetic musing on lost loves and things that have passed. Tzina invites you to physically explore the virtual square, combining elements of fantasy, while experiencing the square in different times of the day.\\nI served as the project’s technical director, in which I got to shoot, develop, write music and implement features in the experience.\",\"cover\":\"tzina.png\",\"credits\":\"Directed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>. Developed with Avner Peled, Ziv Schneider and Laura Juo-Hsin Chen. <a href=\\\"http://tzina.space\\\" target=\\\"_blank\\\">For full credit list</a>\",\"title\":\"Tzina\",\"press\":[[\"Creators Project\",\"https://creators.vice.com/en_us/article/mg44g4/symphony-of-longing-interactive-vr-doc-tel-aviv\"],[\"IDFA DocLab\",\"https://www.doclab.org/2016/tzina-symphony-of-longing/\"],[\"Haaretz\",\"https://www.haaretz.co.il/gallery/cinema/.premium-1.4083991\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/158715900671/tzina-symphony-of-longing-webvr-documentary-by\"],[\"Cannes NEXT\",\"#\"],[\"Doc-Aviv\",\"#\"],[\"Paris Play Film Festival\",\"#\"],[\"Tornto Web Festival\",\"#\"]],\"links\":[[\"Full Experience\",\"http://tzina.space\"],[\"Making-of\",\"https://www.youtube.com/watch?v=n0IIKgNnctY\"],[\"Github\",\"https://github.com/Avnerus/tzina\"]],\"embed\":\"<div style=\\\"padding:56.25% 0 0 0;position:relative;\\\"><iframe src=\\\"https://player.vimeo.com/video/187784291?title=0&byline=0&portrait=0\\\" style=\\\"position:absolute;top:0;left:0;width:100%;height:100%;\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><script src=\\\"https://player.vimeo.com/api/player.js\\\"></script>\",\"tags\":[\"Virtual Reality\"],\"excerpt\":\"A virtual reality documentary about love and lonliness.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/twit.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/twit-ar\",\"title\":\"Twit.AR\",\"links\":[[\"Documentation\",\"http://itp.orfleisher.com/2017/10/21/context-with-twitter-ar/\"],[\"Presskit\",\"http://orfleisher.com/twitter_ar/mediakit.zip\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"http://agermanidis.com\\\">Anastasis Germanidis</a>\",\"press\":[[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/166745203731/twitar-coding-experiment-from-or-fleisher-and\"],[\"Next Reality\",\"https://mobile-ar.reality.news/news/bizarre-ar-experiment-serves-tweets-for-everything-your-iphone-can-see-0180743/\"],[\"Alphr\",\"http://www.alphr.com/twitter/1007491/twitter-in-augmented-reality-looks-like-a-living-nightmare\"]],\"components\":[[\"code\",\"Swift\"],[\"software\",\"Inception v3, CoreML, Twitter API & Swifter\"],[\"3d\",\"ARKit\"]],\"cover\":\"twit.jpg\",\"about\":\"TwitAR is a speculative satirical experiment that examines how Twitter tweets could be visualized in Augmented Reality.\\nTwitAR tries to playfully imagine what would happen if Twitter intruded our everyday reality. The experiment uses Apple’s ARKit to visualize tweets in Augmented Reality on the world itself.\\nTo match the context to what the user is seeing it uses Machine Learning (Apple’s CoreML) to classify the objects you are looking at and pulls tweets from Twitter based on this classification.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/LVnUHWsGEaQ?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Predict how long people have to live in augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Experiment\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/visualiser.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/visualizer\",\"title\":\"Visualizer\",\"links\":[[\"Demo\",\"https://juniorxsound.github.io/ICM-Fall-2016/3D_Web_Audio_Visualiser/\"],[\"Github\",\"https://github.com/juniorxsound/ICM-Fall-2016/tree/master/3D_Web_Audio_Visualiser\"]],\"credits\":\"\",\"press\":[],\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"Blender, e-on Vue, Adobe Photoshop\"],[\"3d\",\"Three.js\"]],\"cover\":\"visualizer.png\",\"about\":\"‘Visualizer’ was born after an R&D process I did with Roey Tsemah and Ronen Tanchum. Initially our goal was to research how we could use the Web Audio API, to analyse incoming signal (music or microphone inputs), and drive geometry deformations in real-time, while keeping performance optimal so it could run on mobile browsers as well.\\nAfter the R&D process was done, I went on to design the concept art for this visualizer, using 3D animation and environment design software packages and then implementing these designs in the web using Three.js. This work was made possible thanks to the amazing post “Experiments with Perlin Noise” examples by Jaume Sanchez.\",\"embed\":\"\",\"excerpt\":\"A 3D web audio sound visulaizer.\",\"tags\":[\"Experiment\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---tzina-d31edae681b1954c7c54.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"DepthKit, e-on Vue, Adobe Photoshop, Autodesk Maya, ffmpeg, Web Audio API and the WebVR API.\"],[\"3d\",\"Three.js\"]],\"path\":\"/tzina\",\"about\":\"In January 2017, Tzina Dizengoff square, one of Tel Aviv’s emblematic sites, was demolished. The square became a home for the lonely and marginalized characters of the area. This project tells the story of the people who gravitated toward the square and spent their days in it. In this interactive webVR documentary, they talk about their lives and the square. Together, they form a poetic musing on lost loves and things that have passed. Tzina invites you to physically explore the virtual square, combining elements of fantasy, while experiencing the square in different times of the day.\\nI served as the project’s technical director, in which I got to shoot, develop, write music and implement features in the experience.\",\"cover\":\"tzina.png\",\"credits\":\"Directed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>. Developed with Avner Peled, Ziv Schneider and Laura Juo-Hsin Chen. <a href=\\\"http://tzina.space\\\" target=\\\"_blank\\\">For full credit list</a>\",\"title\":\"Tzina\",\"press\":[[\"Creators Project\",\"https://creators.vice.com/en_us/article/mg44g4/symphony-of-longing-interactive-vr-doc-tel-aviv\"],[\"IDFA DocLab\",\"https://www.doclab.org/2016/tzina-symphony-of-longing/\"],[\"Haaretz\",\"https://www.haaretz.co.il/gallery/cinema/.premium-1.4083991\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/158715900671/tzina-symphony-of-longing-webvr-documentary-by\"],[\"Cannes NEXT\",\"#\"],[\"Doc-Aviv\",\"#\"],[\"Paris Play Film Festival\",\"#\"],[\"Tornto Web Festival\",\"#\"]],\"links\":[[\"Full Experience\",\"http://tzina.space\"],[\"Making-of\",\"https://www.youtube.com/watch?v=n0IIKgNnctY\"],[\"Github\",\"https://github.com/Avnerus/tzina\"]],\"embed\":\"<div style=\\\"padding:56.25% 0 0 0;position:relative;\\\"><iframe src=\\\"https://player.vimeo.com/video/187784291?title=0&byline=0&portrait=0\\\" style=\\\"position:absolute;top:0;left:0;width:100%;height:100%;\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><script src=\\\"https://player.vimeo.com/api/player.js\\\"></script>\",\"tags\":[\"Virtual Reality\"],\"excerpt\":\"A virtual reality documentary about love and lonliness.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/twit.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/twit-ar\",\"title\":\"Twit.AR\",\"links\":[[\"Documentation\",\"http://itp.orfleisher.com/2017/10/21/context-with-twitter-ar/\"],[\"Presskit\",\"http://orfleisher.com/twitter_ar/mediakit.zip\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"http://agermanidis.com\\\">Anastasis Germanidis</a>\",\"press\":[[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/166745203731/twitar-coding-experiment-from-or-fleisher-and\"],[\"Next Reality\",\"https://mobile-ar.reality.news/news/bizarre-ar-experiment-serves-tweets-for-everything-your-iphone-can-see-0180743/\"],[\"Alphr\",\"http://www.alphr.com/twitter/1007491/twitter-in-augmented-reality-looks-like-a-living-nightmare\"]],\"components\":[[\"code\",\"Swift\"],[\"software\",\"Inception v3, CoreML, Twitter API & Swifter\"],[\"3d\",\"ARKit\"]],\"cover\":\"twit.jpg\",\"about\":\"TwitAR is a speculative satirical experiment that examines how Twitter tweets could be visualized in Augmented Reality.\\nTwitAR tries to playfully imagine what would happen if Twitter intruded our everyday reality. The experiment uses Apple’s ARKit to visualize tweets in Augmented Reality on the world itself.\\nTo match the context to what the user is seeing it uses Machine Learning (Apple’s CoreML) to classify the objects you are looking at and pulls tweets from Twitter based on this classification.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/LVnUHWsGEaQ?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Predict how long people have to live in augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Experiment\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/visualiser.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/visualizer\",\"title\":\"Visualizer\",\"links\":[[\"Demo\",\"https://juniorxsound.github.io/ICM-Fall-2016/3D_Web_Audio_Visualiser/\"],[\"Github\",\"https://github.com/juniorxsound/ICM-Fall-2016/tree/master/3D_Web_Audio_Visualiser\"]],\"credits\":\"\",\"press\":[],\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"Blender, e-on Vue, Adobe Photoshop\"],[\"3d\",\"Three.js\"]],\"cover\":\"visualizer.png\",\"about\":\"‘Visualizer’ was born after an R&D process I did with Roey Tsemah and Ronen Tanchum. Initially our goal was to research how we could use the Web Audio API, to analyse incoming signal (music or microphone inputs), and drive geometry deformations in real-time, while keeping performance optimal so it could run on mobile browsers as well.\\nAfter the R&D process was done, I went on to design the concept art for this visualizer, using 3D animation and environment design software packages and then implementing these designs in the web using Three.js. This work was made possible thanks to the amazing post “Experiments with Perlin Noise” examples by Jaume Sanchez.\",\"embed\":\"\",\"excerpt\":\"A 3D web audio sound visulaizer.\",\"tags\":[\"Experiment\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/tzina.json\n// module id = 396\n// module chunks = 254679725877355"],"sourceRoot":""}