webpackJsonp([0x6c44fe6ca697],{379:function(e,t){e.exports={data:{markdownRemark:{html:"",frontmatter:{date:"June 16, 2018",components:[["code","Swift"],["software","Blender, CoreML, AgeNet"],["3d","ARKit"]],path:"/death-mask",about:"‘Death-Mask’ predicts how long people have to live and overlays that in the form of a “clock” above they’re heads in augmented reality. The project uses a machine learning model titled AgeNet for the prediction process. Once predicted it uses the average life expectancy in that location to try and estimate how long one has left.\nThe aesthetic inspiration derives from the concept of death masks. These are sculptures meant to symbolize the death of a person by casting his face (i.e creating a mask).",cover:"deathmask_cover.png",credits:'Developed with <a target="_blank" href="http://agermanidis.com">Anastasis Germanidis</a>',title:"Death Mask",press:[["Wired","https://www.wired.it/attualita/tech/2017/12/20/death-mask-realta-morte-previsione/"],["UploadVR","https://uploadvr.com/arkit-death-mask/"],["Next Reailty","https://next.reality.news/news/ar-experiment-adds-life-clock-anyone-with-face-0181330/"],["VRInside","https://vrinside.jp/news/death-mask/"],["Shiropen","https://shiropen.com/2017/11/29/29963"],["Owdin","https://owdin.live/2017/11/24/death-mask-combien-dannees-de-vie-vous-reste-t-il-version-realite-augmentee/"],["prosthetic knowledge","http://prostheticknowledge.tumblr.com/post/167809095736/death-mask-programming-project-from-or-fleisher"],["Realite Virtuelle","https://www.realite-virtuelle.com/death-mask-age-mort-2911"]],links:[["Documentation","http://itp.orfleisher.com/2017/11/17/where-is-the-line-with-public-data/"]],embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/OzndnZuvu2c?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',tags:["Augmented Reality","Machine Learning","Experiment"],excerpt:"Predict how long people have to live in augmented reality."}}},pathContext:{prev:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/skeletron.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-06-17T12:23:00+00:02",path:"/skeletron",title:"Skeletron",links:[["Presskit","https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY"]],credits:'Developed with <a target="_blank" href="https://drorayalon.com">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port',press:[["The Next Web","https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/"],["Tech Radar","https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect"],["GeekTime","https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/"],["Android Headlines","https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html"],["FossBytes","https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/"]],components:[["code","C#, HLSL Python"],["software","Unity3D"],["3d","Tensorflow"]],cover:"skeletron.jpg",about:"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).",embed:'<iframe width="100%" height="500" src="https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"Predict joints and human skeleton position from real-time video.",tags:["Machine Learning","Tools"]}},next:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/soundobjects.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-06-15T12:22:00+00:00",path:"/soundobjects",title:"Sound Objects",links:[["Making-of","https://www.youtube.com/watch?v=giU_hnfS8HQ"]],credits:'Developed with <a target="_blank" href="http://www.scottreitherman.com/">Scott Reitherman</a>',press:[],components:[["code","C#, HLSL"],["software","Unity3D, Oculus Rift & Touch SDK"],["3d","Ableton Live, Pure Data, Heavy"]],cover:"so.png",about:"Sound Objects is a music composition app in virtual reality that uses physical objects and collisions to trigger different instruments. The experience challenges our perception of physics by allowing the Sound Objects to bend and defy them, resulting in playful physics that embed musical concepts such as repetition, indeterminism and evolution.",embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/EkB9nE-vQhw?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"Compose music in virtual reality using objects",tags:["Virtual Reality"]}}}}}});
//# sourceMappingURL=path---death-mask-cfb3a36132227c9c25d5.js.map