{"version":3,"sources":["webpack:///path---toolstoolstools-367ab0bf0b599c851c4a.js","webpack:///./.cache/json/toolstoolstools.json"],"names":["webpackJsonp","399","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,gBAAAC,aAAA,6DAAAC,KAAA,mBAAAC,MAAA,sKAAAC,MAAA,sBAAAC,QAAA,iFAAAC,MAAA,mBAAAC,QAAA,wFAAAC,QAAA,kGAAAC,MAAA,GAAAC,MAAA,cAAAC,QAAA,mCAA8tBC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,0GAAAf,aAAwIC,KAAA,4BAAAE,KAAA,WAAAI,MAAA,UAAAE,QAAA,+IAAAH,QAAA,2FAAAE,QAAA,oXAAAN,aAAA,2FAAAG,MAAA,WAAAD,MAAA,2fAAAM,MAAA,oMAA++CE,QAAA,6DAAAD,MAAA,uDAAmLK,MAASjB,KAAA,GAAAgB,GAAA,4GAAAf,aAA0IC,KAAA,4BAAAE,KAAA,UAAAI,MAAA,SAAAE,QAAA,gOAAAH,QAAA,kFAAAE,QAAA,yEAAAN,aAAA,oEAAAG,MAAA,mBAAAD,MAAA,0RAAAM,MAAA,oMAA0hCE,QAAA,4DAAAD,MAAA","file":"path---toolstoolstools-367ab0bf0b599c851c4a.js","sourcesContent":["webpackJsonp([68671615135808],{\n\n/***/ 399:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"June 14, 2018\",\"components\":[[\"code\",\"C++\"],[\"software\",\"ffmpeg\"],[\"3d\",\"openFrameworks\"]],\"path\":\"/toolstoolstools\",\"about\":\"This project is a projected interactive installation. An audio-visual instrument of short animated loops. In homage to the digital toolset of the graphic designer.\",\"cover\":\"toolstoolstools.png\",\"credits\":\"Designed with <a target=\\\"_blank\\\" href=\\\"https://talbaltuch.com\\\">Tal Baltuch</a>\",\"title\":\"ToolsTools.Tools\",\"press\":[[\"Uncanny – Holon Design Museum\",\"http://www.dmh.org.il/pages/default.aspx?PageId=858\"]],\"links\":[[\"Website\",\"https://toolstools.tools\"],[\"Tal Baltuch\",\"http://talbaltuch.com/ToolsTools-Tools-2\"]],\"embed\":\"\",\"tags\":[\"Experiment\"],\"excerpt\":\"An installation about design.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/twit.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-14T12:28:00+00:02\",\"path\":\"/twit-ar\",\"title\":\"Twit.AR\",\"links\":[[\"Documentation\",\"http://itp.orfleisher.com/2017/10/21/context-with-twitter-ar/\"],[\"Presskit\",\"http://orfleisher.com/twitter_ar/mediakit.zip\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"http://agermanidis.com\\\">Anastasis Germanidis</a>\",\"press\":[[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/166745203731/twitar-coding-experiment-from-or-fleisher-and\"],[\"Next Reality\",\"https://mobile-ar.reality.news/news/bizarre-ar-experiment-serves-tweets-for-everything-your-iphone-can-see-0180743/\"],[\"Alphr\",\"http://www.alphr.com/twitter/1007491/twitter-in-augmented-reality-looks-like-a-living-nightmare\"]],\"components\":[[\"code\",\"Swift\"],[\"software\",\"Inception v3, CoreML, Twitter API & Swifter\"],[\"3d\",\"ARKit\"]],\"cover\":\"twit.jpg\",\"about\":\"TwitAR is a speculative satirical experiment that examines how Twitter tweets could be visualized in Augmented Reality.\\nTwitAR tries to playfully imagine what would happen if Twitter intruded our everyday reality. The experiment uses Apple’s ARKit to visualize tweets in Augmented Reality on the world itself.\\nTo match the context to what the user is seeing it uses Machine Learning (Apple’s CoreML) to classify the objects you are looking at and pulls tweets from Twitter based on this classification.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/LVnUHWsGEaQ?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Predict how long people have to live in augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Experiment\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/detune.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-13T12:25:00+00:00\",\"path\":\"/detune\",\"title\":\"detune\",\"links\":[[\"Website\",\"https://detune.app\"],[\"App store\",\"https://itunes.apple.com/us/app/detune-music-with-your-face/id1370740132?mt=8\"],[\"Github\",\"https://github.com/dodiku/detune\"],[\"Presskit\",\"http://www.detuneapp.com/media.html\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://drorayalon.com\\\">Dror Ayalon</a>\",\"press\":[[\"AudioKit\",\"https://audiokitpro.com/detune-play-music-with-your-face/\"]],\"components\":[[\"code\",\"Swift\"],[\"software\",\"AudioKit\"],[\"3d\",\"iPhoneX TrueDepth\"]],\"cover\":\"detune_cover.png\",\"about\":\"detune uses Apple’s ARKit and the TrueDepth camera (currently available only on iPhone X) to trigger music events, and to allow users to play music using face impressions. The motivation behind the project was to make Apple’s TrueDepth camera more accessible for creative coders.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/7xnZwB00mrE?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"detune allows users to play music using face impressions.\",\"tags\":[\"Experiments\",\"Tools\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---toolstoolstools-367ab0bf0b599c851c4a.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"June 14, 2018\",\"components\":[[\"code\",\"C++\"],[\"software\",\"ffmpeg\"],[\"3d\",\"openFrameworks\"]],\"path\":\"/toolstoolstools\",\"about\":\"This project is a projected interactive installation. An audio-visual instrument of short animated loops. In homage to the digital toolset of the graphic designer.\",\"cover\":\"toolstoolstools.png\",\"credits\":\"Designed with <a target=\\\"_blank\\\" href=\\\"https://talbaltuch.com\\\">Tal Baltuch</a>\",\"title\":\"ToolsTools.Tools\",\"press\":[[\"Uncanny – Holon Design Museum\",\"http://www.dmh.org.il/pages/default.aspx?PageId=858\"]],\"links\":[[\"Website\",\"https://toolstools.tools\"],[\"Tal Baltuch\",\"http://talbaltuch.com/ToolsTools-Tools-2\"]],\"embed\":\"\",\"tags\":[\"Experiment\"],\"excerpt\":\"An installation about design.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/twit.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-14T12:28:00+00:02\",\"path\":\"/twit-ar\",\"title\":\"Twit.AR\",\"links\":[[\"Documentation\",\"http://itp.orfleisher.com/2017/10/21/context-with-twitter-ar/\"],[\"Presskit\",\"http://orfleisher.com/twitter_ar/mediakit.zip\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"http://agermanidis.com\\\">Anastasis Germanidis</a>\",\"press\":[[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/166745203731/twitar-coding-experiment-from-or-fleisher-and\"],[\"Next Reality\",\"https://mobile-ar.reality.news/news/bizarre-ar-experiment-serves-tweets-for-everything-your-iphone-can-see-0180743/\"],[\"Alphr\",\"http://www.alphr.com/twitter/1007491/twitter-in-augmented-reality-looks-like-a-living-nightmare\"]],\"components\":[[\"code\",\"Swift\"],[\"software\",\"Inception v3, CoreML, Twitter API & Swifter\"],[\"3d\",\"ARKit\"]],\"cover\":\"twit.jpg\",\"about\":\"TwitAR is a speculative satirical experiment that examines how Twitter tweets could be visualized in Augmented Reality.\\nTwitAR tries to playfully imagine what would happen if Twitter intruded our everyday reality. The experiment uses Apple’s ARKit to visualize tweets in Augmented Reality on the world itself.\\nTo match the context to what the user is seeing it uses Machine Learning (Apple’s CoreML) to classify the objects you are looking at and pulls tweets from Twitter based on this classification.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/LVnUHWsGEaQ?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Predict how long people have to live in augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Experiment\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/detune.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-13T12:25:00+00:00\",\"path\":\"/detune\",\"title\":\"detune\",\"links\":[[\"Website\",\"https://detune.app\"],[\"App store\",\"https://itunes.apple.com/us/app/detune-music-with-your-face/id1370740132?mt=8\"],[\"Github\",\"https://github.com/dodiku/detune\"],[\"Presskit\",\"http://www.detuneapp.com/media.html\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://drorayalon.com\\\">Dror Ayalon</a>\",\"press\":[[\"AudioKit\",\"https://audiokitpro.com/detune-play-music-with-your-face/\"]],\"components\":[[\"code\",\"Swift\"],[\"software\",\"AudioKit\"],[\"3d\",\"iPhoneX TrueDepth\"]],\"cover\":\"detune_cover.png\",\"about\":\"detune uses Apple’s ARKit and the TrueDepth camera (currently available only on iPhone X) to trigger music events, and to allow users to play music using face impressions. The motivation behind the project was to make Apple’s TrueDepth camera more accessible for creative coders.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/7xnZwB00mrE?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"detune allows users to play music using face impressions.\",\"tags\":[\"Experiments\",\"Tools\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/toolstoolstools.json\n// module id = 399\n// module chunks = 68671615135808"],"sourceRoot":""}