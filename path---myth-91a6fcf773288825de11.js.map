{"version":3,"sources":["webpack:///path---myth-91a6fcf773288825de11.js","webpack:///./.cache/json/myth.json"],"names":["webpackJsonp","380","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,eAAAC,aAAA,0KAAAC,KAAA,QAAAC,MAAA,ipBAAAC,MAAA,iBAAAC,QAAA,8DAAAC,MAAA,OAAAC,QAAA,+xBAAAC,QAAA,0JAAAC,MAAA,2WAAkpEC,MAAA,mBAAAC,QAAA,mDAAsPC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,yGAAAf,aAAuIC,KAAA,4BAAAE,KAAA,OAAAI,MAAA,uBAAAE,QAAA,8DAAAH,QAAA,mFAAAE,SAAAN,aAAA,wDAAAG,MAAA,UAAAD,MAAA,6JAAAM,MAAA,GAAAE,QAAA,sCAAAD,MAAA,WAA+kBK,MAASjB,KAAA,GAAAgB,GAAA,6GAAAf,aAA2IC,KAAA,4BAAAE,KAAA,WAAAI,MAAA,UAAAE,QAAA,qDAAAH,QAAA,qIAAAE,SAAAN,aAAA,2DAAAG,MAAA,cAAAD,MAAA,4YAAAM,MAAA,oMAA47BE,QAAA,sCAAAD,MAAA","file":"path---myth-91a6fcf773288825de11.js","sourcesContent":["webpackJsonp([263125549072782],{\n\n/***/ 380:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"May 23, 2018\",\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"Blender, e-on Vue, Adobe Photoshop, Autodesk Maya and Ableton Live, Web Audio API, Web MIDI API & WebVR API.\"],[\"3d\",\"Three.js\"]],\"path\":\"/myth\",\"about\":\"‘Myth’, is an interactive web virtual reality short film, featuring the song “Can I peacfuly Love” from Livyatanim’s debut album “After the Waters”. The film takes place in a dark surreal world, which aims to blur the lines between digital and natural imagery.\\nThe film uses the composition’s notation, rhythms and melodies (MIDI), to control elements ranging from drums affecting the geometry to transitions between scenes. In effect, using this data transformed from being a musical composition language, to a visual directing language.\\nThe experience can be watched on a wide range of platforms from desktop computers, mobile phones and VR headsets.\",\"cover\":\"myth-cover.png\",\"credits\":\"Developed with Yannis Gravezas, Tomer Rousso and Livyatanim\",\"title\":\"Myth\",\"press\":[[\"Wired\",\"https://www.wired.de/collection/life/10-virtual-reality-filme-die-man-gesehen-haben-muss\"],[\"Creators Project\",\"https://creators.vice.com/en_us/article/ez5qva/float-through-a-virtual-world-of-hybrid-beings-in-myth\"],[\"We and the Color\",\"https://weandthecolor.com/webgl-short-film-livyatanim-myth/62302\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/133824524661/myth-interactive-web-music-video-for-livyatanim'\"],[\"Z\",\"http://z.ultranoir.com/en/articles/1282-livyatanim-myth-a-vr-film-by-or-fleisher.html\"],[\"Chrome Experiments\",\"https://experiments.withgoogle.com/livyatanim-myth\"],[\"WorldFest- NASA Remi Award winner\",\"#\"],[\"UrbamMediaMakers Best Interactive Award Winner\",\"#\"],[\"The FWA – WOTD\",\"#\"],[\"CSS Awards – WOTD\",\"#\"],[\"Awwwards – Honorable Mention\",\"#\"]],\"links\":[[\"Full Experience\",\"http://film.livyatanim.com\"],[\"Album\",\"https://livyatanim.bandcamp.com\"],[\"Presskit\",\"http://film.livyatanim.com/media/mediakit.zip\"]],\"embed\":\"<div style=\\\"padding:56.25% 0 0 0;position:relative;\\\"><iframe src=\\\"https://player.vimeo.com/video/145578640?autoplay=0&title=0&byline=0&portrait=0\\\" style=\\\"position:absolute;top:0;left:0;width:100%;height:100%;\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><script src=\\\"https://player.vimeo.com/api/player.js\\\"></script>\",\"tags\":[\"Virtual Reality\"],\"excerpt\":\"An audio reactive virtual reality short film.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/max.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-05-23T12:34:00+00:00\",\"path\":\"/max\",\"title\":\"DepthKit for Max/MSP\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/DepthKit-for-Max\"]],\"credits\":\"Developed with <a href=\\\"https://drorayalon.com\\\" target=\\\"_blank\\\">Dror Ayalon</a>.\",\"press\":[],\"components\":[[\"code\",\"GLSL\"],[\"software\",\"DepthKit\"],[\"3d\",\"Jitter\"]],\"cover\":\"max.png\",\"about\":\"DepthKit for Max is a sample Max patch demonstrating a workflow for playing volumetric videos in Max/Msp/Jitter using DepthKit combined-per-pixel exports.\",\"embed\":\"\",\"excerpt\":\"Render volumetric video in Max/MSP.\",\"tags\":[\"Tools\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/retouch.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/retouch\",\"title\":\"ReTouch\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/ReTouch\"]],\"credits\":\"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University\",\"press\":[],\"components\":[[\"code\",\"C++, GLSL\"],[\"software\",\"Volume\"],[\"3d\",\"OpenGL\"]],\"cover\":\"shining.jpg\",\"about\":\"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Edit and retouch any image in 2.5D.\",\"tags\":[\"Machine Learning\",\"Tools\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---myth-91a6fcf773288825de11.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"May 23, 2018\",\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"Blender, e-on Vue, Adobe Photoshop, Autodesk Maya and Ableton Live, Web Audio API, Web MIDI API & WebVR API.\"],[\"3d\",\"Three.js\"]],\"path\":\"/myth\",\"about\":\"‘Myth’, is an interactive web virtual reality short film, featuring the song “Can I peacfuly Love” from Livyatanim’s debut album “After the Waters”. The film takes place in a dark surreal world, which aims to blur the lines between digital and natural imagery.\\nThe film uses the composition’s notation, rhythms and melodies (MIDI), to control elements ranging from drums affecting the geometry to transitions between scenes. In effect, using this data transformed from being a musical composition language, to a visual directing language.\\nThe experience can be watched on a wide range of platforms from desktop computers, mobile phones and VR headsets.\",\"cover\":\"myth-cover.png\",\"credits\":\"Developed with Yannis Gravezas, Tomer Rousso and Livyatanim\",\"title\":\"Myth\",\"press\":[[\"Wired\",\"https://www.wired.de/collection/life/10-virtual-reality-filme-die-man-gesehen-haben-muss\"],[\"Creators Project\",\"https://creators.vice.com/en_us/article/ez5qva/float-through-a-virtual-world-of-hybrid-beings-in-myth\"],[\"We and the Color\",\"https://weandthecolor.com/webgl-short-film-livyatanim-myth/62302\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/133824524661/myth-interactive-web-music-video-for-livyatanim'\"],[\"Z\",\"http://z.ultranoir.com/en/articles/1282-livyatanim-myth-a-vr-film-by-or-fleisher.html\"],[\"Chrome Experiments\",\"https://experiments.withgoogle.com/livyatanim-myth\"],[\"WorldFest- NASA Remi Award winner\",\"#\"],[\"UrbamMediaMakers Best Interactive Award Winner\",\"#\"],[\"The FWA – WOTD\",\"#\"],[\"CSS Awards – WOTD\",\"#\"],[\"Awwwards – Honorable Mention\",\"#\"]],\"links\":[[\"Full Experience\",\"http://film.livyatanim.com\"],[\"Album\",\"https://livyatanim.bandcamp.com\"],[\"Presskit\",\"http://film.livyatanim.com/media/mediakit.zip\"]],\"embed\":\"<div style=\\\"padding:56.25% 0 0 0;position:relative;\\\"><iframe src=\\\"https://player.vimeo.com/video/145578640?autoplay=0&title=0&byline=0&portrait=0\\\" style=\\\"position:absolute;top:0;left:0;width:100%;height:100%;\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><script src=\\\"https://player.vimeo.com/api/player.js\\\"></script>\",\"tags\":[\"Virtual Reality\"],\"excerpt\":\"An audio reactive virtual reality short film.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/max.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-05-23T12:34:00+00:00\",\"path\":\"/max\",\"title\":\"DepthKit for Max/MSP\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/DepthKit-for-Max\"]],\"credits\":\"Developed with <a href=\\\"https://drorayalon.com\\\" target=\\\"_blank\\\">Dror Ayalon</a>.\",\"press\":[],\"components\":[[\"code\",\"GLSL\"],[\"software\",\"DepthKit\"],[\"3d\",\"Jitter\"]],\"cover\":\"max.png\",\"about\":\"DepthKit for Max is a sample Max patch demonstrating a workflow for playing volumetric videos in Max/Msp/Jitter using DepthKit combined-per-pixel exports.\",\"embed\":\"\",\"excerpt\":\"Render volumetric video in Max/MSP.\",\"tags\":[\"Tools\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/retouch.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:34:00+00:02\",\"path\":\"/retouch\",\"title\":\"ReTouch\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/ReTouch\"]],\"credits\":\"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University\",\"press\":[],\"components\":[[\"code\",\"C++, GLSL\"],[\"software\",\"Volume\"],[\"3d\",\"OpenGL\"]],\"cover\":\"shining.jpg\",\"about\":\"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Edit and retouch any image in 2.5D.\",\"tags\":[\"Machine Learning\",\"Tools\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/myth.json\n// module id = 380\n// module chunks = 263125549072782"],"sourceRoot":""}