{"version":3,"sources":["webpack:///path---skeletron-d268a42f11895d6f7786.js","webpack:///./.cache/json/skeletron.json"],"names":["webpackJsonp","388","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,iBAAAC,aAAA,sEAAAC,KAAA,aAAAC,MAAA,ubAAAC,MAAA,gBAAAC,QAAA,2IAAAC,MAAA,YAAAC,QAAA,kjBAAAC,QAAA,wFAAAC,MAAA,oMAA2kDC,MAAA,4BAAAC,QAAA,sEAAiKC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,gHAAAf,aAA8IC,KAAA,4BAAAE,KAAA,eAAAI,MAAA,cAAAE,QAAA,kLAAAH,QAAA,GAAAE,SAAAN,aAAA,sEAAAG,MAAA,uBAAAD,MAAA,4LAAAM,MAAA,GAAAE,QAAA,iDAAAD,MAAA,iDAAytBK,MAASjB,KAAA,GAAAgB,GAAA,6GAAAf,aAA2IC,KAAA,4BAAAE,KAAA,WAAAI,MAAA,UAAAE,QAAA,qDAAAH,QAAA,qIAAAE,SAAAN,aAAA,2DAAAG,MAAA,cAAAD,MAAA,4YAAAM,MAAA,oMAA47BE,QAAA,sCAAAD,MAAA","file":"path---skeletron-d268a42f11895d6f7786.js","sourcesContent":["webpackJsonp([101821273434762],{\n\n/***/ 388:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"C#, HLSL Python\"],[\"software\",\"Unity3D\"],[\"3d\",\"Tensorflow\"]],\"path\":\"/skeletron\",\"about\":\"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).\",\"cover\":\"skeletron.jpg\",\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://drorayalon.com\\\">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port\",\"title\":\"Skeletron\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/\"],[\"Tech Radar\",\"https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect\"],[\"GeekTime\",\"https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html\"],[\"FossBytes\",\"https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/\"]],\"links\":[[\"Presskit\",\"https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY\"]],\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"500\\\" src=\\\"https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"tags\":[\"Machine Learning\",\"Tools\"],\"excerpt\":\"Predict joints and human skeleton position from real-time video.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/depthkitjs.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:27:00+00:02\",\"path\":\"/depthkit-js\",\"title\":\"DepthKit.js\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/DepthKit.js\"],[\"Documentation\",\"https://juniorxsound.github.io/DepthKit.js/\"],[\"npm package\",\"https://www.npmjs.com/package/depthkit\"]],\"credits\":\"\",\"press\":[],\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"DepthKit\"],[\"3d\",\"Three.js\"]],\"cover\":\"depthkitjs_cover.png\",\"about\":\"DepthKit.js is a plugin for visualising DepthKit volumteric captures using Three.js in WebGL. The plugin requires Three.js and a DepthKit combined-per-pixel video export from Visualise.\",\"embed\":\"\",\"excerpt\":\"A WebVR plugin for rendering volumetric video.\",\"tags\":[\"Augmented Reality\",\"Virtual Reality\",\"Tools\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/retouch.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:21:00+00:02\",\"path\":\"/retouch\",\"title\":\"ReTouch\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/ReTouch\"]],\"credits\":\"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University\",\"press\":[],\"components\":[[\"code\",\"C++, GLSL\"],[\"software\",\"Volume\"],[\"3d\",\"OpenGL\"]],\"cover\":\"shining.jpg\",\"about\":\"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Edit and retouch any image in 2.5D.\",\"tags\":[\"Machine Learning\",\"Tools\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---skeletron-d268a42f11895d6f7786.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"C#, HLSL Python\"],[\"software\",\"Unity3D\"],[\"3d\",\"Tensorflow\"]],\"path\":\"/skeletron\",\"about\":\"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).\",\"cover\":\"skeletron.jpg\",\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://drorayalon.com\\\">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port\",\"title\":\"Skeletron\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/\"],[\"Tech Radar\",\"https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect\"],[\"GeekTime\",\"https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html\"],[\"FossBytes\",\"https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/\"]],\"links\":[[\"Presskit\",\"https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY\"]],\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"500\\\" src=\\\"https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"tags\":[\"Machine Learning\",\"Tools\"],\"excerpt\":\"Predict joints and human skeleton position from real-time video.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/depthkitjs.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:27:00+00:02\",\"path\":\"/depthkit-js\",\"title\":\"DepthKit.js\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/DepthKit.js\"],[\"Documentation\",\"https://juniorxsound.github.io/DepthKit.js/\"],[\"npm package\",\"https://www.npmjs.com/package/depthkit\"]],\"credits\":\"\",\"press\":[],\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"DepthKit\"],[\"3d\",\"Three.js\"]],\"cover\":\"depthkitjs_cover.png\",\"about\":\"DepthKit.js is a plugin for visualising DepthKit volumteric captures using Three.js in WebGL. The plugin requires Three.js and a DepthKit combined-per-pixel video export from Visualise.\",\"embed\":\"\",\"excerpt\":\"A WebVR plugin for rendering volumetric video.\",\"tags\":[\"Augmented Reality\",\"Virtual Reality\",\"Tools\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/retouch.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:21:00+00:02\",\"path\":\"/retouch\",\"title\":\"ReTouch\",\"links\":[[\"Github\",\"https://github.com/juniorxsound/ReTouch\"]],\"credits\":\"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University\",\"press\":[],\"components\":[[\"code\",\"C++, GLSL\"],[\"software\",\"Volume\"],[\"3d\",\"OpenGL\"]],\"cover\":\"shining.jpg\",\"about\":\"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Edit and retouch any image in 2.5D.\",\"tags\":[\"Machine Learning\",\"Tools\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/skeletron.json\n// module id = 388\n// module chunks = 101821273434762"],"sourceRoot":""}