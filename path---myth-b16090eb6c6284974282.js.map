{"version":3,"sources":["webpack:///path---myth-b16090eb6c6284974282.js","webpack:///./.cache/json/myth.json"],"names":["webpackJsonp","385","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,gBAAAC,aAAA,0KAAAC,KAAA,QAAAC,MAAA,ipBAAAC,MAAA,iBAAAC,QAAA,8DAAAC,MAAA,OAAAC,QAAA,+xBAAAC,QAAA,0JAAAC,MAAA,2WAAmpEC,MAAA,mBAAAC,QAAA,mDAAsPC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,4GAAAf,aAA0IC,KAAA,4BAAAE,KAAA,UAAAI,MAAA,SAAAE,QAAA,iNAAAH,QAAA,kFAAAE,QAAA,qbAAAN,aAAA,6IAAAG,MAAA,mBAAAD,MAAA,sgBAAAM,MAAA,GAAAE,QAAA,gEAAAD,MAAA,oEAAoqDK,MAASjB,KAAA,GAAAgB,GAAA,iHAAAf,aAA+IC,KAAA,4BAAAE,KAAA,gBAAAI,MAAA,sBAAAE,QAAA,oOAAAH,QAAA,kFAAAE,QAAA,4+BAAAN,aAAA,sFAAAG,MAAA,iBAAAD,MAAA,+PAAAM,MAAA,oMAAy8DE,QAAA,yEAAAD,MAAA","file":"path---myth-b16090eb6c6284974282.js","sourcesContent":["webpackJsonp([263125549072782],{\n\n/***/ 385:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"June 24, 2018\",\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"Blender, e-on Vue, Adobe Photoshop, Autodesk Maya and Ableton Live, Web Audio API, Web MIDI API & WebVR API.\"],[\"3d\",\"Three.js\"]],\"path\":\"/myth\",\"about\":\"‘Myth’, is an interactive web virtual reality short film, featuring the song “Can I peacfuly Love” from Livyatanim’s debut album “After the Waters”. The film takes place in a dark surreal world, which aims to blur the lines between digital and natural imagery.\\nThe film uses the composition’s notation, rhythms and melodies (MIDI), to control elements ranging from drums affecting the geometry to transitions between scenes. In effect, using this data transformed from being a musical composition language, to a visual directing language.\\nThe experience can be watched on a wide range of platforms from desktop computers, mobile phones and VR headsets.\",\"cover\":\"myth-cover.png\",\"credits\":\"Developed with Yannis Gravezas, Tomer Rousso and Livyatanim\",\"title\":\"Myth\",\"press\":[[\"Wired\",\"https://www.wired.de/collection/life/10-virtual-reality-filme-die-man-gesehen-haben-muss\"],[\"Creators Project\",\"https://creators.vice.com/en_us/article/ez5qva/float-through-a-virtual-world-of-hybrid-beings-in-myth\"],[\"We and the Color\",\"https://weandthecolor.com/webgl-short-film-livyatanim-myth/62302\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/133824524661/myth-interactive-web-music-video-for-livyatanim'\"],[\"Z\",\"http://z.ultranoir.com/en/articles/1282-livyatanim-myth-a-vr-film-by-or-fleisher.html\"],[\"Chrome Experiments\",\"https://experiments.withgoogle.com/livyatanim-myth\"],[\"WorldFest- NASA Remi Award winner\",\"#\"],[\"UrbamMediaMakers Best Interactive Award Winner\",\"#\"],[\"The FWA – WOTD\",\"#\"],[\"CSS Awards – WOTD\",\"#\"],[\"Awwwards – Honorable Mention\",\"#\"]],\"links\":[[\"Full Experience\",\"http://film.livyatanim.com\"],[\"Album\",\"https://livyatanim.bandcamp.com\"],[\"Presskit\",\"http://film.livyatanim.com/media/mediakit.zip\"]],\"embed\":\"<div style=\\\"padding:56.25% 0 0 0;position:relative;\\\"><iframe src=\\\"https://player.vimeo.com/video/145578640?autoplay=0&title=0&byline=0&portrait=0\\\" style=\\\"position:absolute;top:0;left:0;width:100%;height:100%;\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><script src=\\\"https://player.vimeo.com/api/player.js\\\"></script>\",\"tags\":[\"Virtual Reality\"],\"excerpt\":\"An audio reactive virtual reality short film.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/volume.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-25T12:34:00+00:02\",\"path\":\"/volume\",\"title\":\"Volume\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/03/08/try-this-ai-experiment-that-converts-2d-images-to-3d/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/171637247736/volume-online-update-update-to-machine-learning\"],[\"Tecmundo\",\"https://www.tecmundo.com.br/software/127998-ia-transforma-qualquer-foto-modelo-3d-teste.htm\"]],\"components\":[[\"code\",\"Python, Javascript, GLSL, C#, HLSL\"],[\"software\",\"Three.js, Unity3D, Unreal Engine, Blender\"],[\"3d\",\"Tensorflow, Heroku, Firebase\"]],\"cover\":\"volume_cover.jpg\",\"about\":\"Volume is a tool for reconstructing a single 2D image or video in 3D space. Using state-of-the-art machine learning research, Volume is able to generate a 3D asset from a single view. Volume is currently under development and is being built as an end-to-end solution allowing anyone to easily generate a 3D asset and use it in 3D environments. Volume is intended to encourage easy prototyping in virtual, augmented and mixed reality platforms. Volume was used to create the Inside Pulp Fiction project, and ReTouch.\",\"embed\":\"\",\"excerpt\":\"Reconstruct 2D images and video in 3D using machine learning.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Virtual Reality\",\"Tools\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/pulpfiction.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-23T12:31:00+00:02\",\"path\":\"/pulp-fiction\",\"title\":\"Inside Pulp Fiction\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL/Pulp-Fiction-ARKit\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/22/ai-rips-objects-from-video-and-reimagines-them-in-3d-ar/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"Vice\",\"https://motherboard.vice.com/en_us/article/gywamy/cue-up-the-pulp-fiction-dance-scene-this-app-3d-projects-2d-movies-in-your-living-room\"],[\"Mashable\",\"http://mashable.france24.com/tech-business/20180130-films-volume-realite-augmentee-cinema-technologie\"],[\"UploadVR\",\"https://uploadvr.com/ar-app-brings-pulp-fiction-characters-living-room/\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/170014746561/volume-in-development-project-from-or-fleisher\"],[\"VRFocus\",\"https://www.vrfocus.com/2018/01/reconstruct-your-favourite-movie-in-ar/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/volume-ai-program-puts-2d-objects-3d-spaces.html\"],[\"Labroots\",\"https://www.labroots.com/trending/videos/11371/ai-tool-turns-video-into-3d-augmented-reality-experiences\"]],\"components\":[[\"code\",\"Python, C#, HLSL\"],[\"software\",\"Unity3D, Tensorflow\"],[\"3d\",\"ARKit, Volume\"]],\"cover\":\"pulp_cover.jpg\",\"about\":\"Inside Pulp Fiction is an experiment that uses machine learning to reconstruct Pulp Fiction's iconic dance scene in Augmented Reality. The experiment is a part of Volume, a machine learning driven tool to reconstruct 3D models from 2D images and video.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/iwJt4DM6mJA?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Step inside Pulp Fiction's iconic dance scene using augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---myth-b16090eb6c6284974282.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"June 24, 2018\",\"components\":[[\"code\",\"Javascript, GLSL\"],[\"software\",\"Blender, e-on Vue, Adobe Photoshop, Autodesk Maya and Ableton Live, Web Audio API, Web MIDI API & WebVR API.\"],[\"3d\",\"Three.js\"]],\"path\":\"/myth\",\"about\":\"‘Myth’, is an interactive web virtual reality short film, featuring the song “Can I peacfuly Love” from Livyatanim’s debut album “After the Waters”. The film takes place in a dark surreal world, which aims to blur the lines between digital and natural imagery.\\nThe film uses the composition’s notation, rhythms and melodies (MIDI), to control elements ranging from drums affecting the geometry to transitions between scenes. In effect, using this data transformed from being a musical composition language, to a visual directing language.\\nThe experience can be watched on a wide range of platforms from desktop computers, mobile phones and VR headsets.\",\"cover\":\"myth-cover.png\",\"credits\":\"Developed with Yannis Gravezas, Tomer Rousso and Livyatanim\",\"title\":\"Myth\",\"press\":[[\"Wired\",\"https://www.wired.de/collection/life/10-virtual-reality-filme-die-man-gesehen-haben-muss\"],[\"Creators Project\",\"https://creators.vice.com/en_us/article/ez5qva/float-through-a-virtual-world-of-hybrid-beings-in-myth\"],[\"We and the Color\",\"https://weandthecolor.com/webgl-short-film-livyatanim-myth/62302\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/133824524661/myth-interactive-web-music-video-for-livyatanim'\"],[\"Z\",\"http://z.ultranoir.com/en/articles/1282-livyatanim-myth-a-vr-film-by-or-fleisher.html\"],[\"Chrome Experiments\",\"https://experiments.withgoogle.com/livyatanim-myth\"],[\"WorldFest- NASA Remi Award winner\",\"#\"],[\"UrbamMediaMakers Best Interactive Award Winner\",\"#\"],[\"The FWA – WOTD\",\"#\"],[\"CSS Awards – WOTD\",\"#\"],[\"Awwwards – Honorable Mention\",\"#\"]],\"links\":[[\"Full Experience\",\"http://film.livyatanim.com\"],[\"Album\",\"https://livyatanim.bandcamp.com\"],[\"Presskit\",\"http://film.livyatanim.com/media/mediakit.zip\"]],\"embed\":\"<div style=\\\"padding:56.25% 0 0 0;position:relative;\\\"><iframe src=\\\"https://player.vimeo.com/video/145578640?autoplay=0&title=0&byline=0&portrait=0\\\" style=\\\"position:absolute;top:0;left:0;width:100%;height:100%;\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><script src=\\\"https://player.vimeo.com/api/player.js\\\"></script>\",\"tags\":[\"Virtual Reality\"],\"excerpt\":\"An audio reactive virtual reality short film.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/volume.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-25T12:34:00+00:02\",\"path\":\"/volume\",\"title\":\"Volume\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/03/08/try-this-ai-experiment-that-converts-2d-images-to-3d/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/171637247736/volume-online-update-update-to-machine-learning\"],[\"Tecmundo\",\"https://www.tecmundo.com.br/software/127998-ia-transforma-qualquer-foto-modelo-3d-teste.htm\"]],\"components\":[[\"code\",\"Python, Javascript, GLSL, C#, HLSL\"],[\"software\",\"Three.js, Unity3D, Unreal Engine, Blender\"],[\"3d\",\"Tensorflow, Heroku, Firebase\"]],\"cover\":\"volume_cover.jpg\",\"about\":\"Volume is a tool for reconstructing a single 2D image or video in 3D space. Using state-of-the-art machine learning research, Volume is able to generate a 3D asset from a single view. Volume is currently under development and is being built as an end-to-end solution allowing anyone to easily generate a 3D asset and use it in 3D environments. Volume is intended to encourage easy prototyping in virtual, augmented and mixed reality platforms. Volume was used to create the Inside Pulp Fiction project, and ReTouch.\",\"embed\":\"\",\"excerpt\":\"Reconstruct 2D images and video in 3D using machine learning.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Virtual Reality\",\"Tools\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/pulpfiction.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-06-23T12:31:00+00:02\",\"path\":\"/pulp-fiction\",\"title\":\"Inside Pulp Fiction\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL/Pulp-Fiction-ARKit\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/01/22/ai-rips-objects-from-video-and-reimagines-them-in-3d-ar/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"Vice\",\"https://motherboard.vice.com/en_us/article/gywamy/cue-up-the-pulp-fiction-dance-scene-this-app-3d-projects-2d-movies-in-your-living-room\"],[\"Mashable\",\"http://mashable.france24.com/tech-business/20180130-films-volume-realite-augmentee-cinema-technologie\"],[\"UploadVR\",\"https://uploadvr.com/ar-app-brings-pulp-fiction-characters-living-room/\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/170014746561/volume-in-development-project-from-or-fleisher\"],[\"VRFocus\",\"https://www.vrfocus.com/2018/01/reconstruct-your-favourite-movie-in-ar/\"],[\"Android Headlines\",\"https://www.androidheadlines.com/2018/01/volume-ai-program-puts-2d-objects-3d-spaces.html\"],[\"Labroots\",\"https://www.labroots.com/trending/videos/11371/ai-tool-turns-video-into-3d-augmented-reality-experiences\"]],\"components\":[[\"code\",\"Python, C#, HLSL\"],[\"software\",\"Unity3D, Tensorflow\"],[\"3d\",\"ARKit, Volume\"]],\"cover\":\"pulp_cover.jpg\",\"about\":\"Inside Pulp Fiction is an experiment that uses machine learning to reconstruct Pulp Fiction's iconic dance scene in Augmented Reality. The experiment is a part of Volume, a machine learning driven tool to reconstruct 3D models from 2D images and video.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/iwJt4DM6mJA?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"Step inside Pulp Fiction's iconic dance scene using augmented reality.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/myth.json\n// module id = 385\n// module chunks = 263125549072782"],"sourceRoot":""}