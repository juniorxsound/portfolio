webpackJsonp([0xc23a7c76a45e],{396:function(e,t){e.exports={data:{markdownRemark:{html:"",frontmatter:{date:"April 23, 2018",components:[["code","Swift"],["software","Inception v3, CoreML, Twitter API & Swifter"],["3d","ARKit"]],path:"/twit-ar",about:"TwitAR is a speculative satirical experiment that examines how Twitter tweets could be visualized in Augmented Reality.\nTwitAR tries to playfully imagine what would happen if Twitter intruded our everyday reality. The experiment uses Apple’s ARKit to visualize tweets in Augmented Reality on the world itself.\nTo match the context to what the user is seeing it uses Machine Learning (Apple’s CoreML) to classify the objects you are looking at and pulls tweets from Twitter based on this classification.",cover:"twit.jpg",credits:'Developed with <a target="_blank" href="http://agermanidis.com">Anastasis Germanidis</a>',title:"Twit.AR",press:[["prosthetic knowledge","http://prostheticknowledge.tumblr.com/post/166745203731/twitar-coding-experiment-from-or-fleisher-and"],["Next Reality","https://mobile-ar.reality.news/news/bizarre-ar-experiment-serves-tweets-for-everything-your-iphone-can-see-0180743/"],["Alphr","http://www.alphr.com/twitter/1007491/twitter-in-augmented-reality-looks-like-a-living-nightmare"]],links:[["Documentation","http://itp.orfleisher.com/2017/10/21/context-with-twitter-ar/"],["Presskit","http://orfleisher.com/twitter_ar/mediakit.zip"]],embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/LVnUHWsGEaQ?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',tags:["Augmented Reality","Machine Learning","Experiment"],excerpt:"Predict how long people have to live in augmented reality."}}},pathContext:{prev:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/deathmask.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-04-23T12:30:00+00:02",path:"/death-mask",title:"Death Mask",links:[["Documentation","http://itp.orfleisher.com/2017/11/17/where-is-the-line-with-public-data/"]],credits:'Developed with <a target="_blank" href="http://agermanidis.com">Anastasis Germanidis</a>',press:[["Wired","https://www.wired.it/attualita/tech/2017/12/20/death-mask-realta-morte-previsione/"],["UploadVR","https://uploadvr.com/arkit-death-mask/"],["Next Reailty","https://next.reality.news/news/ar-experiment-adds-life-clock-anyone-with-face-0181330/"],["VRInside","https://vrinside.jp/news/death-mask/"],["Shiropen","https://shiropen.com/2017/11/29/29963"],["Owdin","https://owdin.live/2017/11/24/death-mask-combien-dannees-de-vie-vous-reste-t-il-version-realite-augmentee/"],["prosthetic knowledge","http://prostheticknowledge.tumblr.com/post/167809095736/death-mask-programming-project-from-or-fleisher"],["Realite Virtuelle","https://www.realite-virtuelle.com/death-mask-age-mort-2911"]],components:[["code","Swift"],["software","Blender, CoreML, AgeNet"],["3d","ARKit"]],cover:"deathmask_cover.png",about:"‘Death-Mask’ predicts how long people have to live and overlays that in the form of a “clock” above they’re heads in augmented reality. The project uses a machine learning model titled AgeNet for the prediction process. Once predicted it uses the average life expectancy in that location to try and estimate how long one has left.\nThe aesthetic inspiration derives from the concept of death masks. These are sculptures meant to symbolize the death of a person by casting his face (i.e creating a mask).",embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/OzndnZuvu2c?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"Predict how long people have to live in augmented reality.",tags:["Augmented Reality","Machine Learning","Experiment"]}},next:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/depthkitjs.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-04-23T12:27:00+00:02",path:"/depthkit-js",title:"DepthKit.js",links:[["Github","https://github.com/juniorxsound/DepthKit.js"],["Documentation","https://juniorxsound.github.io/DepthKit.js/"],["npm package","https://www.npmjs.com/package/depthkit"]],credits:"",press:[],components:[["code","Javascript, GLSL"],["software","DepthKit"],["3d","Three.js"]],cover:"depthkitjs_cover.png",about:"DepthKit.js is a plugin for visualising DepthKit volumteric captures using Three.js in WebGL. The plugin requires Three.js and a DepthKit combined-per-pixel video export from Visualise.",embed:"",excerpt:"A WebVR plugin for rendering volumetric video.",tags:["Augmented Reality","Virtual Reality","Tools"]}}}}}});
//# sourceMappingURL=path---twit-ar-46d5b1c36b903e91849d.js.map