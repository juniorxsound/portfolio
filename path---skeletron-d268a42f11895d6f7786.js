webpackJsonp([0x5c9b1cd56a8a],{388:function(e,t){e.exports={data:{markdownRemark:{html:"",frontmatter:{date:"April 23, 2018",components:[["code","C#, HLSL Python"],["software","Unity3D"],["3d","Tensorflow"]],path:"/skeletron",about:"Skeletron is a system that predicts joints and human skeleton position from real-time video taken by any RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.\nSkeletron was developed thanks and as a part of NYU ITP Xstory grant (Experiments in Storytelling).",cover:"skeletron.jpg",credits:'Developed with <a target="_blank" href="https://drorayalon.com">Dror Ayalon</a>. <br />Attribution: VNect ML Model VNect TensorFlow Port',title:"Skeletron",press:[["The Next Web","https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/"],["Tech Radar","https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect"],["GeekTime","https://www.geektime.co.il/developers-create-kinect-with-tensorflow-and-webcam/"],["Android Headlines","https://www.androidheadlines.com/2018/01/tensorflow-unity-turn-webcams-into-ai-powered-ar-systems.html"],["FossBytes","https://fossbytes.com/programmers-transform-a-10-webcam-into-microsoft-kinect/"]],links:[["Presskit","https://drive.google.com/drive/folders/18uzf-grMetd9bZPNMHDNs7IZWZHNFmKY"]],embed:'<iframe width="100%" height="500" src="https://www.youtube.com/embed/l_owi316cE8?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',tags:["Machine Learning","Tools"],excerpt:"Predict joints and human skeleton position from real-time video."}}},pathContext:{prev:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/depthkitjs.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-04-23T12:27:00+00:02",path:"/depthkit-js",title:"DepthKit.js",links:[["Github","https://github.com/juniorxsound/DepthKit.js"],["Documentation","https://juniorxsound.github.io/DepthKit.js/"],["npm package","https://www.npmjs.com/package/depthkit"]],credits:"",press:[],components:[["code","Javascript, GLSL"],["software","DepthKit"],["3d","Three.js"]],cover:"depthkitjs_cover.png",about:"DepthKit.js is a plugin for visualising DepthKit volumteric captures using Three.js in WebGL. The plugin requires Three.js and a DepthKit combined-per-pixel video export from Visualise.",embed:"",excerpt:"A WebVR plugin for rendering volumetric video.",tags:["Augmented Reality","Virtual Reality","Tools"]}},next:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/retouch.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-04-23T12:21:00+00:02",path:"/retouch",title:"ReTouch",links:[["Github","https://github.com/juniorxsound/ReTouch"]],credits:"Developed by under the advisement of Prof. Ken Perlin and Prof. Daniele Panozzo @ Computer Science Department, New York University",press:[],components:[["code","C++, GLSL"],["software","Volume"],["3d","OpenGL"]],cover:"shining.jpg",about:"ReTouch is an OpenGL application that enables editing and retouching of images using depth-maps in 2.5D. The depth maps are generated by Volume, a state of the art tool, that uses a CNN (Convolutional Neural Network) to predict depth-maps from 2D images . ReTouch uses these depth-maps to enable the addition of depth of field and color retouching for the foreground and background separately.",embed:'<iframe width="100%" height="450" src="https://www.youtube.com/embed/CAsy_jm85ZY?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"Edit and retouch any image in 2.5D.",tags:["Machine Learning","Tools"]}}}}}});
//# sourceMappingURL=path---skeletron-d268a42f11895d6f7786.js.map