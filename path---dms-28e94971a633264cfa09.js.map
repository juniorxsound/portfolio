{"version":3,"sources":["webpack:///path---dms-28e94971a633264cfa09.js","webpack:///./.cache/json/dms.json"],"names":["webpackJsonp","381","module","exports","data","markdownRemark","html","frontmatter","date","components","path","about","cover","credits","title","press","links","embed","tags","excerpt","pathContext","prev","id","next"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,GAAAC,aAAyBC,KAAA,iBAAAC,aAAA,mHAAAC,KAAA,OAAAC,MAAA,ySAAAC,MAAA,UAAAC,QAAA,GAAAC,MAAA,MAAAC,SAAAC,QAAA,8FAAAC,MAAA,oMAAiyBC,MAAA,cAAAC,QAAA,uCAAoHC,aAAgBC,MAAQf,KAAA,GAAAgB,GAAA,6GAAAf,aAA2IC,KAAA,4BAAAE,KAAA,WAAAI,MAAA,UAAAE,QAAA,+CAAAH,QAAA,iFAAAE,SAAAN,aAAA,gGAAAG,MAAA,cAAAD,MAAA,+dAAAM,MAAA,oMAA8/BE,QAAA,0BAAAD,MAAA,gBAAyGK,MAASjB,KAAA,GAAAgB,GAAA,4GAAAf,aAA0IC,KAAA,4BAAAE,KAAA,UAAAI,MAAA,SAAAE,QAAA,iNAAAH,QAAA,kFAAAE,QAAA,qbAAAN,aAAA,6IAAAG,MAAA,mBAAAD,MAAA,sgBAAAM,MAAA,GAAAE,QAAA,gEAAAD,MAAA","file":"path---dms-28e94971a633264cfa09.js","sourcesContent":["webpackJsonp([208357431000568],{\n\n/***/ 381:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"Arduino, cSound\"],[\"software\",\"Node.js, cSound Node Bindings\"],[\"3d\",\"Ultimaker 2+, Epilog Laser Cutter\"]],\"path\":\"/dms\",\"about\":\"‘DMS’ which stands for Different Modular Synth, is a concept design for a synth system. The concept evolved out self interest in modular synthesis and modular design and became a magnetic module based synth system, which uses body parts terminology as an inspiration for it’s naming convention.\",\"cover\":\"dms.png\",\"credits\":\"\",\"title\":\"DMS\",\"press\":[],\"links\":[[\"Documentation\",\"http://itp.orfleisher.com/2016/12/14/dms-physical-computing-csound-final/\"]],\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/RrmJT7v-Lfk?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"tags\":[\"Experiment\"],\"excerpt\":\"A different modular synth system.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/trumpet.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:18:00+00:02\",\"path\":\"/trumpet\",\"title\":\"Trumpet\",\"links\":[[\"Github\",\"https://github.com/dodiku/trumpet\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"http://drorayalon.com\\\">Dror Ayalon</a>\",\"press\":[],\"components\":[[\"code\",\"Javascript, cSound\"],[\"software\",\"Node.js, cSound Node Bindings\"],[\"3d\",\"Twitter API\"]],\"cover\":\"trumpet.png\",\"about\":\"‘Trumpet’ is a Node.js server that listens to tweets from NYC that contain the words “trump” and “protest” and plays a note for every tweet. I developed ‘Trumpet’ with Dror Ayalon during Spotify’s NYC Monthly Music Hackathon.\\nSince the Hackathon took place on January 21st, 2017, a day after Donald Trump’s inauguration, we knew we wanted to create a generative music composition based on people emotions towards the president elect, and the protests around the inauguration.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/4YlOzWwsXKo?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"The sound of a protest.\",\"tags\":[\"Experiment\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/volume.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-21T12:34:00+00:02\",\"path\":\"/volume\",\"title\":\"Volume\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/03/08/try-this-ai-experiment-that-converts-2d-images-to-3d/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/171637247736/volume-online-update-update-to-machine-learning\"],[\"Tecmundo\",\"https://www.tecmundo.com.br/software/127998-ia-transforma-qualquer-foto-modelo-3d-teste.htm\"]],\"components\":[[\"code\",\"Python, Javascript, GLSL, C#, HLSL\"],[\"software\",\"Three.js, Unity3D, Unreal Engine, Blender\"],[\"3d\",\"Tensorflow, Heroku, Firebase\"]],\"cover\":\"volume_cover.jpg\",\"about\":\"Volume is a tool for reconstructing a single 2D image or video in 3D space. Using state-of-the-art machine learning research, Volume is able to generate a 3D asset from a single view. Volume is currently under development and is being built as an end-to-end solution allowing anyone to easily generate a 3D asset and use it in 3D environments. Volume is intended to encourage easy prototyping in virtual, augmented and mixed reality platforms. Volume was used to create the Inside Pulp Fiction project, and ReTouch.\",\"embed\":\"\",\"excerpt\":\"Reconstruct 2D images and video in 3D using machine learning.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Virtual Reality\",\"Tools\"]}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---dms-28e94971a633264cfa09.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"\",\"frontmatter\":{\"date\":\"April 23, 2018\",\"components\":[[\"code\",\"Arduino, cSound\"],[\"software\",\"Node.js, cSound Node Bindings\"],[\"3d\",\"Ultimaker 2+, Epilog Laser Cutter\"]],\"path\":\"/dms\",\"about\":\"‘DMS’ which stands for Different Modular Synth, is a concept design for a synth system. The concept evolved out self interest in modular synthesis and modular design and became a magnetic module based synth system, which uses body parts terminology as an inspiration for it’s naming convention.\",\"cover\":\"dms.png\",\"credits\":\"\",\"title\":\"DMS\",\"press\":[],\"links\":[[\"Documentation\",\"http://itp.orfleisher.com/2016/12/14/dms-physical-computing-csound-final/\"]],\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/RrmJT7v-Lfk?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"tags\":[\"Experiment\"],\"excerpt\":\"A different modular synth system.\"}}},\"pathContext\":{\"prev\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/trumpet.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-23T12:18:00+00:02\",\"path\":\"/trumpet\",\"title\":\"Trumpet\",\"links\":[[\"Github\",\"https://github.com/dodiku/trumpet\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"http://drorayalon.com\\\">Dror Ayalon</a>\",\"press\":[],\"components\":[[\"code\",\"Javascript, cSound\"],[\"software\",\"Node.js, cSound Node Bindings\"],[\"3d\",\"Twitter API\"]],\"cover\":\"trumpet.png\",\"about\":\"‘Trumpet’ is a Node.js server that listens to tweets from NYC that contain the words “trump” and “protest” and plays a note for every tweet. I developed ‘Trumpet’ with Dror Ayalon during Spotify’s NYC Monthly Music Hackathon.\\nSince the Hackathon took place on January 21st, 2017, a day after Donald Trump’s inauguration, we knew we wanted to create a generative music composition based on people emotions towards the president elect, and the protests around the inauguration.\",\"embed\":\"<iframe width=\\\"100%\\\" height=\\\"450\\\" src=\\\"https://www.youtube.com/embed/4YlOzWwsXKo?rel=0&amp;controls=0&amp;showinfo=0\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\",\"excerpt\":\"The sound of a protest.\",\"tags\":[\"Experiment\"]}},\"next\":{\"html\":\"\",\"id\":\"/home/travis/build/juniorxsound/portfolio/src/pages/projects/volume.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-04-21T12:34:00+00:02\",\"path\":\"/volume\",\"title\":\"Volume\",\"links\":[[\"Website\",\"https://volume.gl\"],[\"Github\",\"https://github.com/Volume-GL\"],[\"Presskit\",\"https://drive.google.com/drive/folders/1XBQgptNAchJr0kUSD0LhzUzxdKnZ4Rud\"],[\"Presentation\",\"https://vimeo.com/270479574\"]],\"credits\":\"Developed with <a target=\\\"_blank\\\" href=\\\"https://shirin.works\\\">~shirin anlen</a>\",\"press\":[[\"The Next Web\",\"https://thenextweb.com/artificial-intelligence/2018/03/08/try-this-ai-experiment-that-converts-2d-images-to-3d/\"],[\"Discovery Channel\",\"https://www.youtube.com/watch?v=Zi4yof2yy04\"],[\"prosthetic knowledge\",\"http://prostheticknowledge.tumblr.com/post/171637247736/volume-online-update-update-to-machine-learning\"],[\"Tecmundo\",\"https://www.tecmundo.com.br/software/127998-ia-transforma-qualquer-foto-modelo-3d-teste.htm\"]],\"components\":[[\"code\",\"Python, Javascript, GLSL, C#, HLSL\"],[\"software\",\"Three.js, Unity3D, Unreal Engine, Blender\"],[\"3d\",\"Tensorflow, Heroku, Firebase\"]],\"cover\":\"volume_cover.jpg\",\"about\":\"Volume is a tool for reconstructing a single 2D image or video in 3D space. Using state-of-the-art machine learning research, Volume is able to generate a 3D asset from a single view. Volume is currently under development and is being built as an end-to-end solution allowing anyone to easily generate a 3D asset and use it in 3D environments. Volume is intended to encourage easy prototyping in virtual, augmented and mixed reality platforms. Volume was used to create the Inside Pulp Fiction project, and ReTouch.\",\"embed\":\"\",\"excerpt\":\"Reconstruct 2D images and video in 3D using machine learning.\",\"tags\":[\"Augmented Reality\",\"Machine Learning\",\"Virtual Reality\",\"Tools\"]}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/dms.json\n// module id = 381\n// module chunks = 208357431000568"],"sourceRoot":""}