webpackJsonp([0xbd45de674942],{377:function(e,t){e.exports={data:{markdownRemark:{html:"",frontmatter:{date:"June 12, 2018",components:[["code","Javascript, GLSL"],["software","DepthKit"],["3d","AFrame"]],path:"/aframe",about:"An A-Frame component for rendering Volumetric videos captured using DepthKit (i.e Kinect + DSLR) in WebVR. The component wraps DepthKit.js which provides a similar interface for Three.js projects.",cover:"aframe_cover.jpg",credits:"",title:"DepthKit for AFrame",press:[],links:[["Github","https://github.com/juniorxsound/DepthKit-A-Frame"],["npm package","https://www.npmjs.com/package/aframe-depthkit"]],embed:"",tags:["Virtual Reality","Tools"],excerpt:"An AFrame component for rendering volumetric video in WebVR"}}},pathContext:{prev:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/detune.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-06-13T12:25:00+00:00",path:"/detune",title:"detune",links:[["Website","https://detune.app"],["App store","https://itunes.apple.com/us/app/detune-music-with-your-face/id1370740132?mt=8"],["Github","https://github.com/dodiku/detune"],["Presskit","http://www.detuneapp.com/media.html"]],credits:'Developed with <a target="_blank" href="https://drorayalon.com">Dror Ayalon</a>',press:[["AudioKit","https://audiokitpro.com/detune-play-music-with-your-face/"]],components:[["code","Swift"],["software","AudioKit"],["3d","iPhoneX TrueDepth"]],cover:"detune_cover.png",about:"detune uses Apple’s ARKit and the TrueDepth camera (currently available only on iPhone X) to trigger music events, and to allow users to play music using face impressions. The motivation behind the project was to make Apple’s TrueDepth camera more accessible for creative coders.",embed:'<iframe width="100%" height="315" src="https://www.youtube.com/embed/7xnZwB00mrE?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>',excerpt:"detune allows users to play music using face impressions.",tags:["Experiments","Tools"]}},next:{html:"",id:"/home/travis/build/juniorxsound/portfolio/src/pages/projects/visualiser.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-06-11T12:19:00+00:02",path:"/visualizer",title:"Visualizer",links:[["Demo","https://juniorxsound.github.io/ICM-Fall-2016/3D_Web_Audio_Visualiser/"],["Github","https://github.com/juniorxsound/ICM-Fall-2016/tree/master/3D_Web_Audio_Visualiser"]],credits:"",press:[],components:[["code","Javascript, GLSL"],["software","Blender, e-on Vue, Adobe Photoshop"],["3d","Three.js"]],cover:"visualizer.png",about:"‘Visualizer’ was born after an R&D process I did with Roey Tsemah and Ronen Tanchum. Initially our goal was to research how we could use the Web Audio API, to analyse incoming signal (music or microphone inputs), and drive geometry deformations in real-time, while keeping performance optimal so it could run on mobile browsers as well.\nAfter the R&D process was done, I went on to design the concept art for this visualizer, using 3D animation and environment design software packages and then implementing these designs in the web using Three.js. This work was made possible thanks to the amazing post “Experiments with Perlin Noise” examples by Jaume Sanchez.",embed:"",excerpt:"A 3D web audio sound visulaizer.",tags:["Experiment"]}}}}}});
//# sourceMappingURL=path---aframe-2dce223aa9e5baadb583.js.map